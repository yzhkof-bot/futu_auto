"""
é—ä¼ è§„åˆ’ Alpha å› å­æŒ–æ˜å™¨ V2

å·¥ä¸šçº§å®ç°:
1. ä½¿ç”¨ Panel æ•°æ®ç»“æ„ï¼ˆæ—¥æœŸ Ã— è‚¡ç¥¨ï¼‰
2. æˆªé¢ IC ä½œä¸ºé€‚åº”åº¦å‡½æ•°
3. è®­ç»ƒé›†/æµ‹è¯•é›†åˆ‡åˆ†
4. å®Œæ•´çš„å› å­è¯„ä¼°
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional, Callable
import warnings
import pickle
import os
import random

warnings.filterwarnings('ignore')

# gplearn å¯¼å…¥
try:
    from gplearn.genetic import SymbolicTransformer
    from gplearn.functions import make_function
    from gplearn.fitness import make_fitness
    GPLEARN_AVAILABLE = True
except ImportError:
    GPLEARN_AVAILABLE = False
    print("è­¦å‘Š: gplearn æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install gplearn")

from .data_manager import PanelDataManager
from .factor_engine import (
    ts_delay, ts_delta, ts_mean, ts_std, ts_max, ts_min, ts_rank, ts_sum,
    ts_zscore, cs_rank, cs_zscore, preprocess_factor
)
from .evaluator import FactorEvaluator, quick_evaluate


# ============================================================
# å·¥ä¸šçº§ gplearn ç®—å­åº“
# ============================================================

# ----------------- åŸºç¡€è¿ç®— -----------------

def _protected_div(x1, x2):
    """ä¿æŠ¤é™¤æ³•"""
    with np.errstate(divide='ignore', invalid='ignore'):
        result = np.where(np.abs(x2) > 1e-10, x1 / x2, 0.0)
        return np.clip(result, -1e6, 1e6)


def _protected_log(x):
    """ä¿æŠ¤å¯¹æ•°"""
    with np.errstate(divide='ignore', invalid='ignore'):
        return np.where(x > 1e-10, np.log(x), 0.0)


def _protected_sqrt(x):
    """ä¿æŠ¤å¹³æ–¹æ ¹"""
    return np.sqrt(np.abs(x))


def _sign(x):
    return np.sign(x)


def _abs(x):
    return np.abs(x)


def _neg(x):
    return -x


def _square(x):
    """å¹³æ–¹"""
    return np.clip(x ** 2, -1e10, 1e10)


def _cube(x):
    """ç«‹æ–¹"""
    return np.clip(x ** 3, -1e10, 1e10)


def _inv(x):
    """å€’æ•°"""
    with np.errstate(divide='ignore', invalid='ignore'):
        return np.where(np.abs(x) > 1e-10, 1.0 / x, 0.0)


def _sigmoid(x):
    """Sigmoid å‡½æ•°"""
    return 1.0 / (1.0 + np.exp(-np.clip(x, -500, 500)))


def _tanh(x):
    """åŒæ›²æ­£åˆ‡"""
    return np.tanh(np.clip(x, -500, 500))


# ----------------- æ¯”è¾ƒè¿ç®— -----------------

def _max2(x1, x2):
    """ä¸¤æ•°å–å¤§"""
    return np.maximum(x1, x2)


def _min2(x1, x2):
    """ä¸¤æ•°å–å°"""
    return np.minimum(x1, x2)


def _gt(x1, x2):
    """å¤§äº (x1 > x2 ? 1 : 0)"""
    return np.where(x1 > x2, 1.0, 0.0)


def _lt(x1, x2):
    """å°äº (x1 < x2 ? 1 : 0)"""
    return np.where(x1 < x2, 1.0, 0.0)


# ----------------- æ»šåŠ¨çª—å£åŸºç¡€å‡½æ•° -----------------

def _rolling_mean(x, window):
    """æ»šåŠ¨å‡å€¼"""
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        result[i] = np.nanmean(x[start:i+1])
    return result


def _rolling_std(x, window):
    """æ»šåŠ¨æ ‡å‡†å·®"""
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        if i - start >= 1:
            result[i] = np.nanstd(x[start:i+1])
        else:
            result[i] = 0
    return result


def _rolling_max(x, window):
    """æ»šåŠ¨æœ€å¤§å€¼"""
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        result[i] = np.nanmax(x[start:i+1])
    return result


def _rolling_min(x, window):
    """æ»šåŠ¨æœ€å°å€¼"""
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        result[i] = np.nanmin(x[start:i+1])
    return result


def _rolling_sum(x, window):
    """æ»šåŠ¨æ±‚å’Œ"""
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        result[i] = np.nansum(x[start:i+1])
    return result


def _rolling_prod(x, window):
    """æ»šåŠ¨ä¹˜ç§¯"""
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        result[i] = np.nanprod(x[start:i+1])
    return np.clip(result, -1e10, 1e10)


def _rolling_rank(x, window):
    """æ»šåŠ¨æ’åï¼ˆç™¾åˆ†ä½ï¼‰"""
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        window_data = x[start:i+1]
        valid = ~np.isnan(window_data)
        if np.sum(valid) > 0:
            # å½“å‰å€¼åœ¨çª—å£å†…çš„æ’åç™¾åˆ†ä½
            result[i] = np.sum(window_data[valid] <= x[i]) / np.sum(valid)
    return result


def _rolling_skew(x, window):
    """æ»šåŠ¨ååº¦"""
    from scipy import stats
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        if i - start >= 2:  # è‡³å°‘3ä¸ªç‚¹
            window_data = x[start:i+1]
            valid = ~np.isnan(window_data)
            if np.sum(valid) >= 3:
                result[i] = stats.skew(window_data[valid])
    return np.nan_to_num(result, nan=0.0)


def _rolling_kurt(x, window):
    """æ»šåŠ¨å³°åº¦"""
    from scipy import stats
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        if i - start >= 3:  # è‡³å°‘4ä¸ªç‚¹
            window_data = x[start:i+1]
            valid = ~np.isnan(window_data)
            if np.sum(valid) >= 4:
                result[i] = stats.kurtosis(window_data[valid])
    return np.nan_to_num(result, nan=0.0)


def _rolling_argmax(x, window):
    """æ»šåŠ¨æœ€å¤§å€¼ä½ç½®ï¼ˆè·ä»Šå¤©æ•°ï¼‰"""
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        window_data = x[start:i+1]
        valid = ~np.isnan(window_data)
        if np.sum(valid) > 0:
            argmax = np.nanargmax(window_data)
            result[i] = len(window_data) - 1 - argmax  # è·ä»Šå¤©æ•°
    return result


def _rolling_argmin(x, window):
    """æ»šåŠ¨æœ€å°å€¼ä½ç½®ï¼ˆè·ä»Šå¤©æ•°ï¼‰"""
    result = np.full_like(x, np.nan, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        window_data = x[start:i+1]
        valid = ~np.isnan(window_data)
        if np.sum(valid) > 0:
            argmin = np.nanargmin(window_data)
            result[i] = len(window_data) - 1 - argmin  # è·ä»Šå¤©æ•°
    return result


def _rolling_corr(x1, x2, window):
    """æ»šåŠ¨ç›¸å…³ç³»æ•°"""
    result = np.full_like(x1, np.nan, dtype=float)
    for i in range(len(x1)):
        start = max(0, i - window + 1)
        if i - start >= 2:
            w1 = x1[start:i+1]
            w2 = x2[start:i+1]
            valid = ~(np.isnan(w1) | np.isnan(w2))
            if np.sum(valid) >= 3:
                corr = np.corrcoef(w1[valid], w2[valid])[0, 1]
                result[i] = corr if not np.isnan(corr) else 0.0
    return np.nan_to_num(result, nan=0.0)


def _rolling_cov(x1, x2, window):
    """æ»šåŠ¨åæ–¹å·®"""
    result = np.full_like(x1, np.nan, dtype=float)
    for i in range(len(x1)):
        start = max(0, i - window + 1)
        if i - start >= 1:
            w1 = x1[start:i+1]
            w2 = x2[start:i+1]
            valid = ~(np.isnan(w1) | np.isnan(w2))
            if np.sum(valid) >= 2:
                result[i] = np.cov(w1[valid], w2[valid])[0, 1]
    return np.nan_to_num(result, nan=0.0)


def _decay_linear(x, window):
    """çº¿æ€§è¡°å‡åŠ æƒå‡å€¼ (è¿‘æœŸæƒé‡å¤§)"""
    result = np.full_like(x, np.nan, dtype=float)
    weights = np.arange(1, window + 1, dtype=float)
    weights = weights / weights.sum()
    for i in range(len(x)):
        start = max(0, i - window + 1)
        window_data = x[start:i+1]
        w = weights[-(len(window_data)):]
        w = w / w.sum()
        result[i] = np.nansum(window_data * w)
    return result


def _decay_exp(x, window, halflife=None):
    """æŒ‡æ•°è¡°å‡åŠ æƒå‡å€¼"""
    if halflife is None:
        halflife = window / 2
    result = np.full_like(x, np.nan, dtype=float)
    alpha = 1 - np.exp(-np.log(2) / halflife)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        window_data = x[start:i+1]
        n = len(window_data)
        weights = np.array([(1 - alpha) ** j for j in range(n - 1, -1, -1)])
        weights = weights / weights.sum()
        result[i] = np.nansum(window_data * weights)
    return result


# ----------------- æ—¶åºç®—å­ï¼ˆå›ºå®šçª—å£ï¼‰-----------------

def _ts_delay_1(x):
    """å»¶è¿Ÿ1å¤©"""
    result = np.roll(x, 1)
    result[0] = x[0]
    return result


def _ts_delay_5(x):
    """å»¶è¿Ÿ5å¤©"""
    result = np.roll(x, 5)
    result[:5] = x[:5]
    return result


def _ts_delay_10(x):
    """å»¶è¿Ÿ10å¤©"""
    result = np.roll(x, 10)
    result[:10] = x[:10]
    return result


def _ts_delay_20(x):
    """å»¶è¿Ÿ20å¤©"""
    result = np.roll(x, 20)
    result[:20] = x[:20]
    return result


def _ts_delta_1(x):
    """1æ—¥å·®åˆ†"""
    return x - _ts_delay_1(x)


def _ts_delta_5(x):
    """5æ—¥å·®åˆ†"""
    return x - _ts_delay_5(x)


def _ts_delta_10(x):
    """10æ—¥å·®åˆ†"""
    return x - _ts_delay_10(x)


def _ts_delta_20(x):
    """20æ—¥å·®åˆ†"""
    return x - _ts_delay_20(x)


# å‡å€¼
def _ts_mean_3(x):
    return _rolling_mean(x, 3)

def _ts_mean_5(x):
    return _rolling_mean(x, 5)

def _ts_mean_10(x):
    return _rolling_mean(x, 10)

def _ts_mean_20(x):
    return _rolling_mean(x, 20)

def _ts_mean_60(x):
    return _rolling_mean(x, 60)


# æ ‡å‡†å·®
def _ts_std_5(x):
    return _rolling_std(x, 5)

def _ts_std_10(x):
    return _rolling_std(x, 10)

def _ts_std_20(x):
    return _rolling_std(x, 20)


# æœ€å¤§æœ€å°
def _ts_max_5(x):
    return _rolling_max(x, 5)

def _ts_max_10(x):
    return _rolling_max(x, 10)

def _ts_max_20(x):
    return _rolling_max(x, 20)

def _ts_min_5(x):
    return _rolling_min(x, 5)

def _ts_min_10(x):
    return _rolling_min(x, 10)

def _ts_min_20(x):
    return _rolling_min(x, 20)


# æ±‚å’Œ
def _ts_sum_5(x):
    return _rolling_sum(x, 5)

def _ts_sum_10(x):
    return _rolling_sum(x, 10)

def _ts_sum_20(x):
    return _rolling_sum(x, 20)


# æ’å
def _ts_rank_5(x):
    return _rolling_rank(x, 5)

def _ts_rank_10(x):
    return _rolling_rank(x, 10)

def _ts_rank_20(x):
    return _rolling_rank(x, 20)


# ååº¦å³°åº¦
def _ts_skew_20(x):
    return _rolling_skew(x, 20)

def _ts_kurt_20(x):
    return _rolling_kurt(x, 20)


# æœ€å€¼ä½ç½®
def _ts_argmax_5(x):
    return _rolling_argmax(x, 5)

def _ts_argmax_10(x):
    return _rolling_argmax(x, 10)

def _ts_argmin_5(x):
    return _rolling_argmin(x, 5)

def _ts_argmin_10(x):
    return _rolling_argmin(x, 10)


# è¡°å‡åŠ æƒ
def _ts_decay_5(x):
    return _decay_linear(x, 5)

def _ts_decay_10(x):
    return _decay_linear(x, 10)

def _ts_decay_20(x):
    return _decay_linear(x, 20)


# ----------------- åŒå˜é‡æ—¶åºç®—å­ -----------------

def _ts_corr_10(x1, x2):
    return _rolling_corr(x1, x2, 10)

def _ts_corr_20(x1, x2):
    return _rolling_corr(x1, x2, 20)

def _ts_cov_10(x1, x2):
    return _rolling_cov(x1, x2, 10)

def _ts_cov_20(x1, x2):
    return _rolling_cov(x1, x2, 20)


# ----------------- å¤åˆç®—å­ -----------------

def _ts_zscore_10(x):
    """10æ—¥ Z-Score æ ‡å‡†åŒ–"""
    mean = _rolling_mean(x, 10)
    std = _rolling_std(x, 10)
    with np.errstate(divide='ignore', invalid='ignore'):
        result = np.where(std > 1e-10, (x - mean) / std, 0.0)
    return np.clip(result, -5, 5)


def _ts_zscore_20(x):
    """20æ—¥ Z-Score æ ‡å‡†åŒ–"""
    mean = _rolling_mean(x, 20)
    std = _rolling_std(x, 20)
    with np.errstate(divide='ignore', invalid='ignore'):
        result = np.where(std > 1e-10, (x - mean) / std, 0.0)
    return np.clip(result, -5, 5)


def _ts_pctchange_1(x):
    """1æ—¥æ”¶ç›Šç‡"""
    prev = _ts_delay_1(x)
    with np.errstate(divide='ignore', invalid='ignore'):
        result = np.where(np.abs(prev) > 1e-10, (x - prev) / prev, 0.0)
    return np.clip(result, -1, 1)


def _ts_pctchange_5(x):
    """5æ—¥æ”¶ç›Šç‡"""
    prev = _ts_delay_5(x)
    with np.errstate(divide='ignore', invalid='ignore'):
        result = np.where(np.abs(prev) > 1e-10, (x - prev) / prev, 0.0)
    return np.clip(result, -1, 1)


def _ts_momentum_10(x):
    """10æ—¥åŠ¨é‡ (å½“å‰å€¼ / 10æ—¥å‰å€¼)"""
    prev = _ts_delay_10(x)
    with np.errstate(divide='ignore', invalid='ignore'):
        result = np.where(np.abs(prev) > 1e-10, x / prev, 1.0)
    return np.clip(result, 0.1, 10)


def _ts_momentum_20(x):
    """20æ—¥åŠ¨é‡"""
    prev = _ts_delay_20(x)
    with np.errstate(divide='ignore', invalid='ignore'):
        result = np.where(np.abs(prev) > 1e-10, x / prev, 1.0)
    return np.clip(result, 0.1, 10)


# ============================================================
# GP Alpha æŒ–æ˜å™¨ V2
# ============================================================

class GPAlphaMinerV2:
    """
    é—ä¼ è§„åˆ’ Alpha å› å­æŒ–æ˜å™¨ V2
    
    å·¥ä¸šçº§å®ç°ï¼Œä½¿ç”¨æˆªé¢æ•°æ®å’Œ IC è¯„ä¼°
    """
    
    def __init__(self,
                 population_size: int = 2000,
                 generations: int = 50,
                 tournament_size: int = 7,
                 p_crossover: float = 0.85,
                 p_subtree_mutation: float = 0.08,
                 p_hoist_mutation: float = 0.03,
                 p_point_mutation: float = 0.04,
                 max_samples: float = 0.9,
                 parsimony_coefficient: float = 0.0003,
                 init_depth: Tuple[int, int] = (3, 8),
                 random_state: int = 42,
                 n_jobs: int = -1,
                 verbose: int = 1):
        """
        åˆå§‹åŒ–ï¼ˆå·¥ä¸šçº§é»˜è®¤å‚æ•°ï¼‰
        
        Args:
            population_size: ç§ç¾¤å¤§å° (å·¥ä¸šçº§: 2000-5000)
            generations: è¿›åŒ–ä»£æ•° (å·¥ä¸šçº§: 50-100)
            tournament_size: é”¦æ ‡èµ›å¤§å° (å·¥ä¸šçº§: 5-10ï¼Œè¶Šå°å¤šæ ·æ€§è¶Šé«˜)
            p_crossover: äº¤å‰æ¦‚ç‡ (å·¥ä¸šçº§: 0.8-0.9)
            p_subtree_mutation: å­æ ‘å˜å¼‚æ¦‚ç‡
            p_hoist_mutation: æå‡å˜å¼‚æ¦‚ç‡
            p_point_mutation: ç‚¹å˜å¼‚æ¦‚ç‡
            max_samples: æ ·æœ¬é‡‡æ ·æ¯”ä¾‹
            parsimony_coefficient: ç®€æ´æ€§æƒ©ç½šç³»æ•° (å·¥ä¸šçº§: 0.0001-0.0005)
            init_depth: åˆå§‹æ ‘æ·±åº¦èŒƒå›´ (å·¥ä¸šçº§: (3, 8))
            random_state: éšæœºç§å­
            n_jobs: å¹¶è¡Œæ•°
            verbose: è¾“å‡ºè¯¦ç»†ç¨‹åº¦
        """
        self.population_size = population_size
        self.generations = generations
        self.tournament_size = tournament_size
        self.p_crossover = p_crossover
        self.p_subtree_mutation = p_subtree_mutation
        self.p_hoist_mutation = p_hoist_mutation
        self.p_point_mutation = p_point_mutation
        self.max_samples = max_samples
        self.parsimony_coefficient = parsimony_coefficient
        self.init_depth = init_depth
        self.random_state = random_state
        self.n_jobs = n_jobs
        self.verbose = verbose
        
        # æ•°æ®
        self.data_manager: Optional[PanelDataManager] = None
        self.train_dm: Optional[PanelDataManager] = None
        self.test_dm: Optional[PanelDataManager] = None
        
        # ç»“æœ
        self.best_programs = []
        self.best_factors: List[Dict] = []
        self.gp_model = None
        
        # åˆå§‹åŒ–å‡½æ•°é›†
        self._init_function_set()
    
    def _init_function_set(self):
        """åˆå§‹åŒ– gplearn å·¥ä¸šçº§å‡½æ•°é›†"""
        if not GPLEARN_AVAILABLE:
            return
        
        # åˆ›å»ºè‡ªå®šä¹‰å‡½æ•°
        self.gp_functions = [
            # ==================== åŸºç¡€è¿ç®— (9ä¸ª) ====================
            'add', 'sub', 'mul',
            make_function(function=_protected_div, name='div', arity=2),
            make_function(function=_protected_log, name='log', arity=1),
            make_function(function=_protected_sqrt, name='sqrt', arity=1),
            make_function(function=_sign, name='sign', arity=1),
            make_function(function=_abs, name='abs', arity=1),
            make_function(function=_neg, name='neg', arity=1),
            
            # ==================== æ‰©å±•è¿ç®— (6ä¸ª) ====================
            make_function(function=_square, name='square', arity=1),
            make_function(function=_inv, name='inv', arity=1),
            make_function(function=_sigmoid, name='sigmoid', arity=1),
            make_function(function=_tanh, name='tanh', arity=1),
            make_function(function=_max2, name='max2', arity=2),
            make_function(function=_min2, name='min2', arity=2),
            
            # ==================== å»¶è¿Ÿç®—å­ (4ä¸ª) ====================
            make_function(function=_ts_delay_1, name='delay1', arity=1),
            make_function(function=_ts_delay_5, name='delay5', arity=1),
            make_function(function=_ts_delay_10, name='delay10', arity=1),
            make_function(function=_ts_delay_20, name='delay20', arity=1),
            
            # ==================== å·®åˆ†ç®—å­ (4ä¸ª) ====================
            make_function(function=_ts_delta_1, name='delta1', arity=1),
            make_function(function=_ts_delta_5, name='delta5', arity=1),
            make_function(function=_ts_delta_10, name='delta10', arity=1),
            make_function(function=_ts_delta_20, name='delta20', arity=1),
            
            # ==================== å‡å€¼ç®—å­ (5ä¸ª) ====================
            make_function(function=_ts_mean_3, name='mean3', arity=1),
            make_function(function=_ts_mean_5, name='mean5', arity=1),
            make_function(function=_ts_mean_10, name='mean10', arity=1),
            make_function(function=_ts_mean_20, name='mean20', arity=1),
            make_function(function=_ts_mean_60, name='mean60', arity=1),
            
            # ==================== æ ‡å‡†å·®ç®—å­ (3ä¸ª) ====================
            make_function(function=_ts_std_5, name='std5', arity=1),
            make_function(function=_ts_std_10, name='std10', arity=1),
            make_function(function=_ts_std_20, name='std20', arity=1),
            
            # ==================== æœ€å¤§å€¼ç®—å­ (3ä¸ª) ====================
            make_function(function=_ts_max_5, name='max5', arity=1),
            make_function(function=_ts_max_10, name='max10', arity=1),
            make_function(function=_ts_max_20, name='max20', arity=1),
            
            # ==================== æœ€å°å€¼ç®—å­ (3ä¸ª) ====================
            make_function(function=_ts_min_5, name='min5', arity=1),
            make_function(function=_ts_min_10, name='min10', arity=1),
            make_function(function=_ts_min_20, name='min20', arity=1),
            
            # ==================== æ±‚å’Œç®—å­ (3ä¸ª) ====================
            make_function(function=_ts_sum_5, name='sum5', arity=1),
            make_function(function=_ts_sum_10, name='sum10', arity=1),
            make_function(function=_ts_sum_20, name='sum20', arity=1),
            
            # ==================== æ’åç®—å­ (3ä¸ª) ====================
            make_function(function=_ts_rank_5, name='rank5', arity=1),
            make_function(function=_ts_rank_10, name='rank10', arity=1),
            make_function(function=_ts_rank_20, name='rank20', arity=1),
            
            # ==================== é«˜é˜¶ç»Ÿè®¡ (2ä¸ª) ====================
            make_function(function=_ts_skew_20, name='skew20', arity=1),
            make_function(function=_ts_kurt_20, name='kurt20', arity=1),
            
            # ==================== æœ€å€¼ä½ç½® (4ä¸ª) ====================
            make_function(function=_ts_argmax_5, name='argmax5', arity=1),
            make_function(function=_ts_argmax_10, name='argmax10', arity=1),
            make_function(function=_ts_argmin_5, name='argmin5', arity=1),
            make_function(function=_ts_argmin_10, name='argmin10', arity=1),
            
            # ==================== è¡°å‡åŠ æƒ (3ä¸ª) ====================
            make_function(function=_ts_decay_5, name='decay5', arity=1),
            make_function(function=_ts_decay_10, name='decay10', arity=1),
            make_function(function=_ts_decay_20, name='decay20', arity=1),
            
            # ==================== Z-Score æ ‡å‡†åŒ– (2ä¸ª) ====================
            make_function(function=_ts_zscore_10, name='zscore10', arity=1),
            make_function(function=_ts_zscore_20, name='zscore20', arity=1),
            
            # ==================== æ”¶ç›Šç‡/åŠ¨é‡ (4ä¸ª) ====================
            make_function(function=_ts_pctchange_1, name='pctchg1', arity=1),
            make_function(function=_ts_pctchange_5, name='pctchg5', arity=1),
            make_function(function=_ts_momentum_10, name='mom10', arity=1),
            make_function(function=_ts_momentum_20, name='mom20', arity=1),
            
            # ==================== åŒå˜é‡æ—¶åº (4ä¸ª) ====================
            make_function(function=_ts_corr_10, name='corr10', arity=2),
            make_function(function=_ts_corr_20, name='corr20', arity=2),
            make_function(function=_ts_cov_10, name='cov10', arity=2),
            make_function(function=_ts_cov_20, name='cov20', arity=2),
        ]
        
        print(f"å·²åŠ è½½ {len(self.gp_functions)} ä¸ªç®—å­")
    
    def load_data(self,
                  pool_type: str = 'all',
                  start_date: str = None,
                  end_date: str = None,
                  train_ratio: float = 0.7,
                  use_cache: bool = True) -> 'GPAlphaMinerV2':
        """
        åŠ è½½æ•°æ®
        
        Args:
            pool_type: è‚¡ç¥¨æ± ç±»å‹
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        
        Returns:
            self
        """
        print("=" * 60)
        print("åŠ è½½æ•°æ®")
        print("=" * 60)
        
        # è·å–æ•°æ®
        self.data_manager = PanelDataManager()
        self.data_manager.fetch(
            pool_type=pool_type,
            start_date=start_date,
            end_date=end_date,
            use_cache=use_cache,
            verbose=True
        )
        
        # åˆ‡åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†
        self.train_dm, self.test_dm = self.data_manager.split_train_test(train_ratio)
        
        print(f"\nè®­ç»ƒé›†: {len(self.train_dm.dates)} å¤© ({self.train_dm.start_date} ~ {self.train_dm.end_date})")
        print(f"æµ‹è¯•é›†: {len(self.test_dm.dates)} å¤© ({self.test_dm.start_date} ~ {self.test_dm.end_date})")
        
        return self
    
    def _prepare_training_data(self, 
                               dm: PanelDataManager,
                               forward_days: int = 1) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        
        å°† Panel æ•°æ®è½¬æ¢ä¸º gplearn éœ€è¦çš„æ ¼å¼ï¼š
        - æŒ‰è‚¡ç¥¨å±•å¼€ï¼Œæ¯åªè‚¡ç¥¨çš„æ—¶åºæ•°æ®æ‹¼æ¥
        - X: (æ ·æœ¬æ•°, ç‰¹å¾æ•°)
        - y: (æ ·æœ¬æ•°,) æœªæ¥æ”¶ç›Š
        
        Args:
            dm: æ•°æ®ç®¡ç†å™¨
            forward_days: é¢„æµ‹å¤©æ•°
        
        Returns:
            (X, y, feature_names)
        """
        features = dm.get_feature_panels()
        forward_return = dm.get_forward_return(forward_days)
        
        feature_names = list(features.keys())
        
        # æŒ‰è‚¡ç¥¨æ‹¼æ¥
        X_list = []
        y_list = []
        
        for symbol in dm.symbols:
            # æå–è¯¥è‚¡ç¥¨çš„æ‰€æœ‰ç‰¹å¾
            symbol_features = []
            for fname in feature_names:
                if symbol in features[fname].columns:
                    symbol_features.append(features[fname][symbol].values)
                else:
                    symbol_features.append(np.full(len(dm.dates), np.nan))
            
            X_symbol = np.column_stack(symbol_features)
            
            # æœªæ¥æ”¶ç›Š
            if symbol in forward_return.columns:
                y_symbol = forward_return[symbol].values
            else:
                y_symbol = np.full(len(dm.dates), np.nan)
            
            # è¿‡æ»¤æ— æ•ˆè¡Œ
            valid = ~(np.any(np.isnan(X_symbol), axis=1) | np.isnan(y_symbol))
            
            X_list.append(X_symbol[valid])
            y_list.append(y_symbol[valid])
        
        X = np.vstack(X_list)
        y = np.concatenate(y_list)
        
        return X, y, feature_names
    
    def _create_ic_fitness(self, y_true: np.ndarray) -> Callable:
        """
        åˆ›å»º IC é€‚åº”åº¦å‡½æ•°
        
        æ³¨æ„ï¼šgplearn çš„é€‚åº”åº¦å‡½æ•°éœ€è¦æœ€å°åŒ–
        """
        def ic_fitness(y, y_pred, sample_weight):
            """è®¡ç®—è´Ÿ ICï¼ˆç”¨äºæœ€å°åŒ–ï¼‰"""
            from scipy import stats
            
            # è¿‡æ»¤æ— æ•ˆå€¼
            valid = ~(np.isnan(y_pred) | np.isinf(y_pred))
            if np.sum(valid) < 50:
                return 1.0  # æƒ©ç½šæ— æ•ˆå› å­
            
            try:
                ic, _ = stats.spearmanr(y_pred[valid], y[valid])
                if np.isnan(ic):
                    return 1.0
                return -abs(ic)  # å–ç»å¯¹å€¼ï¼Œå› ä¸ºè´Ÿ IC ä¹Ÿæœ‰ä»·å€¼
            except:
                return 1.0
        
        return make_fitness(function=ic_fitness, greater_is_better=False)
    
    def mine(self,
             forward_days: int = 1,
             top_n: int = 10) -> List[Dict]:
        """
        æ‰§è¡Œå› å­æŒ–æ˜
        
        Args:
            forward_days: é¢„æµ‹æœªæ¥æ”¶ç›Šå¤©æ•°
            top_n: è¿”å›æœ€ä½³å› å­æ•°é‡
        
        Returns:
            æœ€ä½³å› å­åˆ—è¡¨
        """
        if not GPLEARN_AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£… gplearn: pip install gplearn")
        
        if self.train_dm is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨ load_data() åŠ è½½æ•°æ®")
        
        print("\n" + "=" * 60)
        print("é—ä¼ è§„åˆ’å› å­æŒ–æ˜ V2")
        print("=" * 60)
        print(f"ç§ç¾¤å¤§å°: {self.population_size}")
        print(f"è¿›åŒ–ä»£æ•°: {self.generations}")
        print(f"é¢„æµ‹å¤©æ•°: {forward_days}")
        print(f"è¿”å›å› å­: {top_n}")
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        print("\nå‡†å¤‡è®­ç»ƒæ•°æ®...")
        X_train, y_train, feature_names = self._prepare_training_data(
            self.train_dm, forward_days
        )
        print(f"è®­ç»ƒæ ·æœ¬: {len(X_train)}")
        print(f"ç‰¹å¾æ•°é‡: {len(feature_names)}")
        print(f"ç‰¹å¾åˆ—è¡¨: {feature_names}")
        
        # åˆ›å»ºé€‚åº”åº¦å‡½æ•°
        fitness = self._create_ic_fitness(y_train)
        
        # åˆ›å»º GP æ¨¡å‹
        print("\nå¼€å§‹è¿›åŒ–...")
        print("-" * 60)
        
        self.gp_model = SymbolicTransformer(
            population_size=self.population_size,
            generations=self.generations,
            tournament_size=self.tournament_size,
            stopping_criteria=-1.0,  # è®¾ä¸º -1 ç¦ç”¨æ—©åœï¼ˆå› ä¸ºæˆ‘ä»¬çš„ fitness æ˜¯è´Ÿå€¼ï¼‰
            p_crossover=self.p_crossover,
            p_subtree_mutation=self.p_subtree_mutation,
            p_hoist_mutation=self.p_hoist_mutation,
            p_point_mutation=self.p_point_mutation,
            max_samples=self.max_samples,
            parsimony_coefficient=self.parsimony_coefficient,
            init_depth=self.init_depth,
            function_set=self.gp_functions,
            feature_names=feature_names,
            metric=fitness,
            n_components=top_n,
            random_state=self.random_state,
            n_jobs=self.n_jobs,
            verbose=self.verbose
        )
        
        # è®­ç»ƒï¼ˆæ”¯æŒä¸­æ–­ä¿å­˜ï¼‰
        try:
            self.gp_model.fit(X_train, y_train)
        except KeyboardInterrupt:
            print("\n" + "=" * 60)
            print("âš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ï¼Œä¿å­˜å½“å‰æœ€ä½³ç»“æœ...")
            print("=" * 60)
        
        # æå–æœ€ä½³å› å­ï¼ˆæ— è®ºæ˜¯å¦ä¸­æ–­éƒ½æ‰§è¡Œï¼‰
        self._extract_and_evaluate_factors(forward_days, feature_names, top_n)
        
        return self.best_factors
    
    def _extract_and_evaluate_factors(self, forward_days: int, feature_names: List[str], top_n: int):
        """æå–å¹¶è¯„ä¼°æœ€ä½³å› å­"""
        print("\n" + "=" * 60)
        print(f"è¯„ä¼° Top {top_n} å› å­")
        print("=" * 60)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœ
        if not hasattr(self.gp_model, '_best_programs') or self.gp_model._best_programs is None:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆå› å­")
            return
        
        self.best_programs = [p for p in self.gp_model._best_programs if p is not None]
        
        if not self.best_programs:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆå› å­")
            return
            
        self.best_factors = []
        
        for i, program in enumerate(self.best_programs):
            print(f"\n[å› å­ #{i+1}]")
            print(f"  å…¬å¼: {program}")
            print(f"  å¤æ‚åº¦: é•¿åº¦={program.length_}, æ·±åº¦={program.depth_}")
            
            # åœ¨è®­ç»ƒé›†ä¸Šè¯„ä¼°
            train_metrics = self._evaluate_program(
                program, self.train_dm, forward_days, feature_names, "è®­ç»ƒé›†"
            )
            
            # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
            test_metrics = self._evaluate_program(
                program, self.test_dm, forward_days, feature_names, "æµ‹è¯•é›†"
            )
            
            factor_info = {
                'rank': i + 1,
                'formula': str(program),
                'length': program.length_,
                'depth': program.depth_,
                'train_metrics': train_metrics,
                'test_metrics': test_metrics,
                'program': program,
            }
            
            self.best_factors.append(factor_info)
        
        # æŒ‰æµ‹è¯•é›†å¾—åˆ†æ’åº
        self.best_factors.sort(
            key=lambda x: x['test_metrics'].get('composite_score', 0),
            reverse=True
        )
        
        # æ›´æ–°æ’å
        for i, f in enumerate(self.best_factors):
            f['rank'] = i + 1
    
    def _evaluate_program(self,
                          program,
                          dm: PanelDataManager,
                          forward_days: int,
                          feature_names: List[str],
                          dataset_name: str) -> Dict:
        """
        è¯„ä¼°å•ä¸ªå› å­ç¨‹åº
        
        Args:
            program: gplearn ç¨‹åº
            dm: æ•°æ®ç®¡ç†å™¨
            forward_days: é¢„æµ‹å¤©æ•°
            feature_names: ç‰¹å¾ååˆ—è¡¨
            dataset_name: æ•°æ®é›†åç§°
        
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        features = dm.get_feature_panels()
        forward_return = dm.get_forward_return(forward_days)
        
        # è®¡ç®—å› å­é¢æ¿
        factor_panel = pd.DataFrame(index=dm.dates, columns=dm.symbols, dtype=float)
        
        for symbol in dm.symbols:
            # æå–è¯¥è‚¡ç¥¨çš„ç‰¹å¾
            symbol_features = []
            for fname in feature_names:
                if symbol in features[fname].columns:
                    symbol_features.append(features[fname][symbol].values)
                else:
                    symbol_features.append(np.full(len(dm.dates), np.nan))
            
            X_symbol = np.column_stack(symbol_features)
            
            # è¿‡æ»¤æ— æ•ˆè¡Œ
            valid = ~np.any(np.isnan(X_symbol), axis=1)
            
            # è®¡ç®—å› å­å€¼
            factor_values = np.full(len(dm.dates), np.nan)
            if np.sum(valid) > 0:
                try:
                    factor_values[valid] = program.execute(X_symbol[valid])
                except:
                    pass
            
            factor_panel[symbol] = factor_values
        
        # é¢„å¤„ç†å› å­
        factor_panel = preprocess_factor(factor_panel)
        
        # è¯„ä¼°
        try:
            evaluator = FactorEvaluator(factor_panel, forward_return, forward_days)
            metrics = evaluator.evaluate(verbose=False)
            
            print(f"  {dataset_name}: IC={metrics['ic_mean']:.4f}, "
                  f"ICIR={metrics['ic_ir']:.4f}, "
                  f"Sharpe={metrics['long_short_sharpe']:.2f}, "
                  f"Score={metrics['composite_score']:.4f}")
            
            return metrics
        except Exception as e:
            print(f"  {dataset_name}: è¯„ä¼°å¤±è´¥ - {e}")
            return {'composite_score': 0}
    
    def get_factor_panel(self, 
                         factor_idx: int = 0,
                         dm: PanelDataManager = None) -> pd.DataFrame:
        """
        è·å–å› å­é¢æ¿
        
        Args:
            factor_idx: å› å­ç´¢å¼•ï¼ˆ0 ä¸ºæœ€ä½³ï¼‰
            dm: æ•°æ®ç®¡ç†å™¨ï¼Œé»˜è®¤ä½¿ç”¨å…¨é‡æ•°æ®
        
        Returns:
            å› å­é¢æ¿ DataFrame
        """
        if not self.best_factors:
            raise ValueError("è¯·å…ˆè°ƒç”¨ mine() æŒ–æ˜å› å­")
        
        if dm is None:
            dm = self.data_manager
        
        program = self.best_factors[factor_idx]['program']
        features = dm.get_feature_panels()
        feature_names = list(features.keys())
        
        factor_panel = pd.DataFrame(index=dm.dates, columns=dm.symbols, dtype=float)
        
        for symbol in dm.symbols:
            symbol_features = []
            for fname in feature_names:
                if symbol in features[fname].columns:
                    symbol_features.append(features[fname][symbol].values)
                else:
                    symbol_features.append(np.full(len(dm.dates), np.nan))
            
            X_symbol = np.column_stack(symbol_features)
            valid = ~np.any(np.isnan(X_symbol), axis=1)
            
            factor_values = np.full(len(dm.dates), np.nan)
            if np.sum(valid) > 0:
                try:
                    factor_values[valid] = program.execute(X_symbol[valid])
                except:
                    pass
            
            factor_panel[symbol] = factor_values
        
        return preprocess_factor(factor_panel)
    
    def print_summary(self, top_n: int = 5):
        """æ‰“å°ç»“æœæ‘˜è¦"""
        if not self.best_factors:
            print("æ— å› å­ç»“æœ")
            return
        
        print("\n" + "=" * 70)
        print("ğŸ† æœ€ä½³å› å­æ±‡æ€»ï¼ˆæŒ‰æµ‹è¯•é›†å¾—åˆ†æ’åºï¼‰")
        print("=" * 70)
        
        for f in self.best_factors[:top_n]:
            train = f['train_metrics']
            test = f['test_metrics']
            
            print(f"\n[#{f['rank']}] {f['formula']}")
            print(f"    å¤æ‚åº¦: é•¿åº¦={f['length']}, æ·±åº¦={f['depth']}")
            print(f"    è®­ç»ƒé›†: IC={train.get('ic_mean', 0):.4f}, "
                  f"ICIR={train.get('ic_ir', 0):.4f}, "
                  f"Sharpe={train.get('long_short_sharpe', 0):.2f}")
            print(f"    æµ‹è¯•é›†: IC={test.get('ic_mean', 0):.4f}, "
                  f"ICIR={test.get('ic_ir', 0):.4f}, "
                  f"Sharpe={test.get('long_short_sharpe', 0):.2f}")
            print(f"    ç»¼åˆå¾—åˆ†: è®­ç»ƒ={train.get('composite_score', 0):.4f}, "
                  f"æµ‹è¯•={test.get('composite_score', 0):.4f}")
    
    def save(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        save_data = {
            'best_factors': [
                {k: v for k, v in f.items() if k != 'program'}
                for f in self.best_factors
            ],
            'params': {
                'population_size': self.population_size,
                'generations': self.generations,
            }
        }
        
        # ä¿å­˜ç¨‹åºï¼ˆå•ç‹¬å¤„ç†ï¼‰
        if self.gp_model is not None:
            save_data['gp_model'] = self.gp_model
        
        with open(filepath, 'wb') as f:
            pickle.dump(save_data, f)
        
        print(f"æ¨¡å‹å·²ä¿å­˜è‡³ {filepath}")
    
    def load(self, filepath: str):
        """åŠ è½½æ¨¡å‹"""
        with open(filepath, 'rb') as f:
            save_data = pickle.load(f)
        
        self.best_factors = save_data.get('best_factors', [])
        self.gp_model = save_data.get('gp_model', None)
        
        if self.gp_model is not None:
            self.best_programs = [p for p in self.gp_model._best_programs if p is not None]
            
            # æ¢å¤ program å¼•ç”¨
            for i, f in enumerate(self.best_factors):
                if i < len(self.best_programs):
                    f['program'] = self.best_programs[i]
        
        print(f"æ¨¡å‹å·²åŠ è½½: {len(self.best_factors)} ä¸ªå› å­")


def quick_mine(pool_type: str = 'nasdaq100',
               population_size: int = 300,
               generations: int = 15,
               forward_days: int = 5,
               top_n: int = 5) -> List[Dict]:
    """
    å¿«é€ŸæŒ–æ˜å…¥å£
    
    Args:
        pool_type: è‚¡ç¥¨æ± ç±»å‹
        population_size: ç§ç¾¤å¤§å°
        generations: è¿›åŒ–ä»£æ•°
        forward_days: é¢„æµ‹å¤©æ•°
        top_n: è¿”å›å› å­æ•°
    
    Returns:
        æœ€ä½³å› å­åˆ—è¡¨
    """
    miner = GPAlphaMinerV2(
        population_size=population_size,
        generations=generations,
        verbose=1
    )
    
    miner.load_data(pool_type=pool_type, train_ratio=0.7)
    factors = miner.mine(forward_days=forward_days, top_n=top_n)
    miner.print_summary(top_n)
    
    return factors


if __name__ == '__main__':
    # æµ‹è¯•
    factors = quick_mine(
        pool_type='nasdaq100',
        population_size=200,
        generations=10,
        forward_days=5,
        top_n=5
    )
